{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UKPN Dashboard Data Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime, time, timedelta\n",
    "import calendar\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/raj/ocf/pv-solar-farm-forecasting/ukpn/scripts\")\n",
    "\n",
    "from resample_data import load_csv_to_pandas, count_total_gsp_solar, interpolation_pandas\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Count - GSP Data\n",
    "\n",
    "# Plotting a bar graph\n",
    "folder_destination = \"/home/raj/ocf/pv-solar-farm-forecasting/tests/data/ukpn_dashboard_data\"\n",
    "count_dict = count_total_gsp_solar(folder_destination = folder_destination)\n",
    "bar_labels = list(count_dict.keys())\n",
    "bar_values = list(count_dict.values())\n",
    "\n",
    "# plotting using seaborn\n",
    "sns.set_theme(style='darkgrid', rc={'figure.dpi': 147},              \n",
    "              font_scale=0.7)\n",
    "fig, ax = plt.subplots(figsize=(7, 2))\n",
    "ax.set_title(\" Total count of the GSP data as of Today (18/01/2023)\")\n",
    "sns.barplot(x = bar_labels, y = bar_values, ax = ax)\n",
    "ax.set(xlabel = \"GSP's\", ylabel = \"Count\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Canterbury Metered power generation for the current month (18/01/2023)\n",
    "\n",
    "# Loading the file\n",
    "path_to_file = \"/home/raj/ocf/pv-solar-farm-forecasting/tests/data/ukpn_dashboard_data/canterbury_north.csv\"\n",
    "canterbury_df = load_csv_to_pandas(path_to_file = path_to_file)\n",
    "\n",
    "# Getting the 2023 Jan data\n",
    "canterbury_df_jan = canterbury_df[canterbury_df.index.year == 2023]\n",
    "canterbury_df_jan = canterbury_df_jan[np.in1d(canterbury_df_jan.index.day.values, [15,16,17])]\n",
    "\n",
    "# Sunrise and Sunset time\n",
    "sunrise_time = time(7, 50)\n",
    "sunrise_time = canterbury_df_jan[np.in1d(canterbury_df_jan.index.time, sunrise_time)].index.values\n",
    "sunset_time = time(16,20)\n",
    "sunset_time = canterbury_df_jan[np.in1d(canterbury_df_jan.index.time, sunset_time)].index.values\n",
    "\n",
    "def legend_without_duplicate_labels(figure):\n",
    "    \"\"\"Prevents legend labels from duplicating\n",
    "    link - https://stackoverflow.com/questions/19385639/duplicate-items-in-legend-in-matplotlib\n",
    "    \"\"\"\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    figure.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "# Plotting\n",
    "sns.lineplot(data = canterbury_df_jan, linewidth = 1.5)\n",
    "for i in range(len(sunrise_time)):\n",
    "    plt.axvline(sunrise_time[i], linewidth = 1.5, color = 'orange', linestyle = '--', label = 'sunrise')\n",
    "    plt.axvline(sunset_time[i], linewidth = 1.5, color = 'red', linestyle = '--', label = 'sunset')\n",
    "    # Naming legend\n",
    "    legend_without_duplicate_labels(plt)\n",
    "    plt.title(\"Timeseries data of Power Genearion (MW) - Canterbury North\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Metered Power Generation (MW)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of power generated by seasons\n",
    "\n",
    "# Loading the file\n",
    "path_to_file = \"/home/raj/ocf/pv-solar-farm-forecasting/tests/data/ukpn_dashboard_data/canterbury_north.csv\"\n",
    "canterbury_df = load_csv_to_pandas(path_to_file = path_to_file)\n",
    "\n",
    "# Resetting the index\n",
    "canterbury_df.reset_index(inplace=True)\n",
    "\n",
    "# Defining Seasons\n",
    "seasons = {\n",
    "    1 : \"Winter\",\n",
    "    2 : \"Winter\",\n",
    "    3 : \"Spring\",\n",
    "    4 : \"Spring\",\n",
    "    5 : \"Spring\",\n",
    "    6 : \"Summer\",\n",
    "    7 : \"Summer\",\n",
    "    8 : \"Summer\",\n",
    "    9 : \"Autumn\",\n",
    "    10 : \"Autumn\",\n",
    "    11 : \"Autumn\",\n",
    "    12 : \"Winter\"\n",
    "}\n",
    "# Getting the data for only 2022\n",
    "canterbury_df_2022 = canterbury_df[canterbury_df[\"date_time\"].dt.year == 2022].reset_index(drop=True)\n",
    "\n",
    "# Getting the data for the mid-day 11am to 1pm\n",
    "canterbury_df_2022 = canterbury_df_2022.set_index(\"date_time\")\n",
    "canterbury_df_2022  = canterbury_df_2022.between_time('11:00', '13:00')\n",
    "\n",
    "# Getting the average for a single day\n",
    "canterbury_avg_2022 = canterbury_df_2022.groupby([\n",
    "    canterbury_df_2022.index.month, canterbury_df_2022.index.day])[\"canterbury_north\"].mean().to_frame()\n",
    "\n",
    "# Getting the seasons of the year\n",
    "canterbury_avg_2022.index.set_names(['month' , 'date'], inplace = True)\n",
    "canterbury_avg_2022.reset_index(inplace = True)\n",
    "canterbury_avg_2022[\"season\"] = canterbury_avg_2022[\"month\"].apply(lambda month_number: seasons[month_number])\n",
    "canterbury_avg_2022[\"month\"] = canterbury_avg_2022[\"month\"].apply(lambda month_number: calendar.month_abbr[month_number])\n",
    "\n",
    "# Plot the data\n",
    "# This plot classifies the average power generated on every mid-day (11am - 1pm) of a season day\n",
    "# For example, the first bar represents the average of 1st day of every month in a season\n",
    "ax = sns.barplot(data = canterbury_avg_2022, x = 'date', y = 'canterbury_north', hue = \"season\", ci = None)\n",
    "ax.set_xlabel('Typical days of a month', fontsize = 10)\n",
    "ax.set_ylabel('Average Power Generated (MW)', fontsize = 10)\n",
    "ax.axes.set_title(\"Mid-day avg power(MW) generated in 2022 - Canterbury North\", fontsize = 12)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     canterbury_north\n",
      "date_time                            \n",
      "2022-08-20 00:00:00             0.029\n",
      "2022-08-20 00:10:00             0.029\n",
      "2022-08-20 00:20:00             0.086\n",
      "2022-08-20 00:30:00             0.086\n",
      "2022-08-20 00:40:00             0.086\n",
      "...                               ...\n",
      "2022-08-20 23:10:00            -0.059\n",
      "2022-08-20 23:20:00            -0.063\n",
      "2022-08-20 23:30:00            -0.067\n",
      "2022-08-20 23:40:00            -0.071\n",
      "2022-08-20 23:50:00            -0.075\n",
      "\n",
      "[144 rows x 1 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "interpolation_pandas() got an unexpected keyword argument 'drop_last_row'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m start_date \u001b[39m=\u001b[39m select_dates[i]\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m end_date \u001b[39m=\u001b[39m (datetime\u001b[39m.\u001b[39mstrptime(start_date, \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m timedelta(days \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m interpolated_df \u001b[39m=\u001b[39m interpolation_pandas(\n\u001b[1;32m     52\u001b[0m     original_df \u001b[39m=\u001b[39;49m filter_df, \n\u001b[1;32m     53\u001b[0m     start_date \u001b[39m=\u001b[39;49m start_date,\n\u001b[1;32m     54\u001b[0m     end_date \u001b[39m=\u001b[39;49m end_date,\n\u001b[1;32m     55\u001b[0m     freq \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m10Min\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     56\u001b[0m     drop_last_row \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     58\u001b[0m final_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([final_dataframe, interpolated_df])\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(final_dataframe)\n",
      "\u001b[0;31mTypeError\u001b[0m: interpolation_pandas() got an unexpected keyword argument 'drop_last_row'"
     ]
    }
   ],
   "source": [
    "# Plotting the negative values before and after interpolation\n",
    "def check_for_negative_data(\n",
    "    original_df: pd.DataFrame,\n",
    "    replace_with_nan: bool = False\n",
    "    ):\n",
    "    \"\"\"This function helps in indentifying if there are any neagtive values\n",
    "\n",
    "    Args:\n",
    "        original_df: Loaded dataframe from the csv file\n",
    "        replace_with_nan: If truem it replaces negative values with NaN's\n",
    "    \"\"\"\n",
    "    # Check for the negative values\n",
    "    check_non_negative = (original_df < 0).any()\n",
    "    if not check_non_negative[0]:\n",
    "        print(f\"The CSV file does contain the negative values {check_for_negative_data}\")\n",
    "    else:\n",
    "        # Filtering the dataframe which has negative values\n",
    "        negative_df = original_df.iloc[np.where(original_df[original_df.columns[0]].values < 0.)]        \n",
    "        if not replace_with_nan:\n",
    "            # Returns index values where there are negative numbers\n",
    "            return negative_df.index\n",
    "        else:     \n",
    "            # Replacing negative values with NaN's\n",
    "            original_df.loc[negative_df.index] = np.nan\n",
    "            # Returns original dataframe with negative values replaced with NaN's\n",
    "            return original_df\n",
    "\n",
    "\n",
    "# Loading the file\n",
    "path_to_file = \"/home/raj/ocf/pv-solar-farm-forecasting/tests/data/ukpn_dashboard_data/canterbury_north.csv\"\n",
    "canterbury_df = load_csv_to_pandas(path_to_file = path_to_file)\n",
    "\n",
    "\n",
    "# Getting the indices of the negative values\n",
    "canterbury_negative_indices = check_for_negative_data(original_df = canterbury_df)\n",
    "unique_dates_with_negative = canterbury_negative_indices.map(lambda t: t.date()).unique()\n",
    "\n",
    "# Selecting random dates\n",
    "select_dates = random.sample(unique_dates_with_negative.to_list(), 1)\n",
    "\n",
    "# Getting the required dataframe\n",
    "final_dataframe = pd.DataFrame([])\n",
    "\n",
    "for i in range(len(select_dates)):\n",
    "    # Filtering dataframe based on each date with negative values\n",
    "    filter_df = canterbury_df.loc[pd.to_datetime(canterbury_df.index.values).date == select_dates[i]]\n",
    "    print(filter_df)\n",
    "    # Interpolating the missing values\n",
    "    start_date = select_dates[i].strftime(\"%Y-%m-%d\")\n",
    "    end_date = (datetime.strptime(start_date, \"%Y-%m-%d\") + timedelta(days = 1)).strftime(\"%Y-%m-%d\")\n",
    "    interpolated_df = interpolation_pandas(\n",
    "        original_df = filter_df, \n",
    "        start_date = start_date,\n",
    "        end_date = end_date,\n",
    "        freq = \"10Min\",\n",
    "        drop_last_row = True)\n",
    "    \n",
    "    final_dataframe = pd.concat([final_dataframe, interpolated_df])\n",
    "    print(final_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.date_range(start=\"2017-01-01\", end=\"2017-01-02\", freq=\"10Min\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_plot(\n",
    "    path_to_file: str\n",
    "    ):\n",
    "    # Getting the original data frame\n",
    "    original_df = load_csv_to_pandas(path_to_file=path_to_file)\n",
    "\n",
    "    # Getting the slopes of every two rows for the entire data frame column\n",
    "    original_df[\"slope\"] = original_df[\"test\"].rolling(window = 2).apply(lambda x: x[1]-x[0])\n",
    "    original_df[\"slope\"] = original_df[\"slope\"].fillna(0)\n",
    "\n",
    "    # Getting the dates of the days with slopes range \n",
    "    active_timestamps = original_df[~original_df[\"slope\"].between(-1.5, 1.5)]\n",
    "\n",
    "    # Getting the most common times of the data with active power\n",
    "    active_timestamps = active_timestamps.index.time\n",
    "    print(np.unique(active_timestamps))\n",
    "    \n",
    "\n",
    "    # derivative = original_df[original_df.columns[0]].diff() / original_df.index.to_series().diff().dt.total_seconds()\n",
    "    # original_df[\"trend\"] = derivative.gt(0).map({False : '-1', True : '1'})\n",
    "    # print(original_df.head(20))\n",
    "    original_df = original_df.head(144)\n",
    "    original_df.plot(y=\"test\", use_index=True)\n",
    "    plt.xlabel(\"Date Range\")\n",
    "    plt.ylabel(\"Gnenerated metered power (MW)\")\n",
    "    plt.title(\"Time series data of power generated\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datapipes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc15a9732967cffaa4d4cd0edd598fb1421042d1e389ff84b912c1fc2b13e168"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
